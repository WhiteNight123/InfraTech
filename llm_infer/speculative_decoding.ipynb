{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtbkgPCQc3uhepkSF3VjJK"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 投机推理（Speculative Decoding）\n",
        "\n",
        "相关文章链接：[LLM提速利器：投机推理的原理与常见方案](https://zhuanlan.zhihu.com/p/1978037808544370747)\n",
        "\n",
        "示例内容：\n",
        "* 投机推理原理演示\n",
        "* Ngram原理演示\n",
        "* vLLM的示例\n",
        "\n",
        "\n",
        "Author: kaiyuan\n",
        "\n",
        "Email: kyxie@zju.edu.cn"
      ],
      "metadata": {
        "id": "ncno-K4UZ4eG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 投机推理原理演示\n",
        "\n",
        "模拟草稿模型+大模型：草稿模型推理，大模型负责验证。\n",
        "\n",
        "可修改每次推理的字符个数：默认3个\n",
        "\n",
        "spec_sim.speculative_step(3)  # 每次提议3个字符"
      ],
      "metadata": {
        "id": "8M4gnpjJZ5hu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xesYaD0NYPwz",
        "outputId": "9d26e11d-fb08-4668-e128-cbd2aee95204"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " 拒绝采样优化演示\n",
            "============================================================\n",
            "目标文本: 人工智能是未来科技发展的核心驱动力。\n",
            "\n",
            "传统生成 vs 投机推理对比:\n",
            "\n",
            "1. 传统大模型生成（逐个字符）:\n",
            "   步骤 1: 生成 '人' -> '人'\n",
            "   步骤 2: 生成 '工' -> '人工'\n",
            "   步骤 3: 生成 '智' -> '人工智'\n",
            "   步骤 4: 生成 '能' -> '人工智能'\n",
            "   步骤 5: 生成 '是' -> '人工智能是'\n",
            "   步骤 6: 生成 '未' -> '人工智能是未'\n",
            "   步骤 7: 生成 '来' -> '人工智能是未来'\n",
            "   步骤 8: 生成 '科' -> '人工智能是未来科'\n",
            "   步骤 9: 生成 '技' -> '人工智能是未来科技'\n",
            "   步骤 10: 生成 '发' -> '人工智能是未来科技发'\n",
            "   步骤 11: 生成 '展' -> '人工智能是未来科技发展'\n",
            "   步骤 12: 生成 '的' -> '人工智能是未来科技发展的'\n",
            "   步骤 13: 生成 '核' -> '人工智能是未来科技发展的核'\n",
            "   步骤 14: 生成 '心' -> '人工智能是未来科技发展的核心'\n",
            "   步骤 15: 生成 '驱' -> '人工智能是未来科技发展的核心驱'\n",
            "   步骤 16: 生成 '动' -> '人工智能是未来科技发展的核心驱动'\n",
            "   步骤 17: 生成 '力' -> '人工智能是未来科技发展的核心驱动力'\n",
            "   步骤 18: 生成 '。' -> '人工智能是未来科技发展的核心驱动力。'\n",
            "\n",
            "2. 投机推理生成（小模型提议，大模型验证）:\n",
            "\n",
            "============================================================\n",
            "步骤 1: 当前已生成: ''\n",
            "目标剩余: '人工智能是未来科技发展的核心驱动力。'\n",
            "小模型生成: '八工智'\n",
            "----------------------------------------\n",
            "大模型验证: 验证结果: 拒绝 | 有效部分: ''\n",
            "✗ 全部拒绝，继续尝试...\n",
            "\n",
            "============================================================\n",
            "步骤 2: 当前已生成: ''\n",
            "目标剩余: '人工智能是未来科技发展的核心驱动力。'\n",
            "小模型生成: '人干智'\n",
            "----------------------------------------\n",
            "大模型验证: 验证结果: 拒绝 | 有效部分: '人'\n",
            "✓ 接受: '人'\n",
            "更新文本: '人'\n",
            "\n",
            "============================================================\n",
            "步骤 3: 当前已生成: '人'\n",
            "目标剩余: '工智能是未来科技发展的核心驱动力。'\n",
            "小模型生成: '工智能'\n",
            "----------------------------------------\n",
            "大模型验证: 验证结果: 通过 | 有效部分: '工智能'\n",
            "✓ 接受: '工智能'\n",
            "更新文本: '人工智能'\n",
            "\n",
            "============================================================\n",
            "步骤 4: 当前已生成: '人工智能'\n",
            "目标剩余: '是未来科技发展的核心驱动力。'\n",
            "小模型生成: '是未来'\n",
            "----------------------------------------\n",
            "大模型验证: 验证结果: 通过 | 有效部分: '是未来'\n",
            "✓ 接受: '是未来'\n",
            "更新文本: '人工智能是未来'\n",
            "\n",
            "============================================================\n",
            "步骤 5: 当前已生成: '人工智能是未来'\n",
            "目标剩余: '科技发展的核心驱动力。'\n",
            "小模型生成: '科技发'\n",
            "----------------------------------------\n",
            "大模型验证: 验证结果: 通过 | 有效部分: '科技发'\n",
            "✓ 接受: '科技发'\n",
            "更新文本: '人工智能是未来科技发'\n",
            "\n",
            "============================================================\n",
            "步骤 6: 当前已生成: '人工智能是未来科技发'\n",
            "目标剩余: '展的核心驱动力。'\n",
            "小模型生成: '展的核'\n",
            "----------------------------------------\n",
            "大模型验证: 验证结果: 通过 | 有效部分: '展的核'\n",
            "✓ 接受: '展的核'\n",
            "更新文本: '人工智能是未来科技发展的核'\n",
            "\n",
            "============================================================\n",
            "步骤 7: 当前已生成: '人工智能是未来科技发展的核'\n",
            "目标剩余: '心驱动力。'\n",
            "小模型生成: '芯驱动'\n",
            "----------------------------------------\n",
            "大模型验证: 验证结果: 拒绝 | 有效部分: ''\n",
            "✗ 全部拒绝，继续尝试...\n",
            "→ 回退策略: 接受单字符 '心'\n",
            "更新文本: '人工智能是未来科技发展的核心'\n",
            "\n",
            "============================================================\n",
            "步骤 8: 当前已生成: '人工智能是未来科技发展的核心'\n",
            "目标剩余: '驱动力。'\n",
            "小模型生成: '区力九'\n",
            "----------------------------------------\n",
            "大模型验证: 验证结果: 拒绝 | 有效部分: ''\n",
            "✗ 全部拒绝，继续尝试...\n",
            "→ 回退策略: 接受单字符 '驱'\n",
            "更新文本: '人工智能是未来科技发展的核心驱'\n",
            "\n",
            "============================================================\n",
            "步骤 9: 当前已生成: '人工智能是未来科技发展的核心驱'\n",
            "目标剩余: '动力。'\n",
            "小模型生成: '动力。'\n",
            "----------------------------------------\n",
            "大模型验证: 验证结果: 通过 | 有效部分: '动力。'\n",
            "✓ 接受: '动力。'\n",
            "更新文本: '人工智能是未来科技发展的核心驱动力。'\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import time\n",
        "from typing import List, Tuple, Callable\n",
        "\n",
        "class SpeculativeInferenceSimulator:\n",
        "    def __init__(self, target_text: str = \"人工智能是未来科技发展的核心驱动力。\"):\n",
        "        self.target_text = target_text\n",
        "        self.current_index = 0\n",
        "        self.generated_text = \"\"\n",
        "        self.steps_log = []\n",
        "\n",
        "    def small_model_generate(self, num_chars: int = 3) -> str:\n",
        "        \"\"\"小模型生成函数 - 有一定概率生成正确文本\"\"\"\n",
        "        if self.current_index >= len(self.target_text):\n",
        "            return \"\"\n",
        "\n",
        "        # 模拟小模型的生成：70%概率生成正确，30%概率生成近似字符\n",
        "        remaining = self.target_text[self.current_index:]\n",
        "        candidate_length = min(num_chars, len(remaining))\n",
        "\n",
        "        # 构建候选文本\n",
        "        candidate = \"\"\n",
        "        for i in range(candidate_length):\n",
        "            correct_char = remaining[i]\n",
        "            # 小模型生成逻辑\n",
        "            if random.random() < 0.7:  # 70%概率生成正确字符\n",
        "                candidate += correct_char\n",
        "            else:\n",
        "                # 生成相似但可能错误的字符\n",
        "                similar_chars = self._get_similar_chars(correct_char)\n",
        "                candidate += random.choice(similar_chars)\n",
        "\n",
        "        return candidate\n",
        "\n",
        "    def large_model_validate(self, candidate: str) -> Tuple[bool, str]:\n",
        "        \"\"\"大模型验证函数 - 高准确率验证\"\"\"\n",
        "        if not candidate:\n",
        "            return False, \"\"\n",
        "\n",
        "        remaining = self.target_text[self.current_index:]\n",
        "\n",
        "        # 逐字符验证\n",
        "        for i, char in enumerate(candidate):\n",
        "            if i >= len(remaining):\n",
        "                return False, \"\"\n",
        "\n",
        "            if char == remaining[i]:\n",
        "                continue\n",
        "            else:\n",
        "                # 验证失败，返回正确的部分\n",
        "                return False, candidate[:i]\n",
        "\n",
        "        return True, candidate\n",
        "\n",
        "    def _get_similar_chars(self, char: str) -> List[str]:\n",
        "        \"\"\"获取相似字符（用于模拟小模型错误）\"\"\"\n",
        "        similarity_map = {\n",
        "            \"人\": [\"人\", \"入\", \"八\"],\n",
        "            \"工\": [\"工\", \"二\", \"干\"],\n",
        "            \"智\": [\"智\", \"知\", \"日\"],\n",
        "            \"能\": [\"能\", \"熊\", \"态\"],\n",
        "            \"是\": [\"是\", \"定\", \"日\"],\n",
        "            \"未\": [\"未\", \"末\", \"木\"],\n",
        "            \"来\": [\"来\", \"米\", \"夹\"],\n",
        "            \"科\": [\"科\", \"料\", \"和\"],\n",
        "            \"技\": [\"技\", \"枝\", \"支\"],\n",
        "            \"发\": [\"发\", \"友\", \"皮\"],\n",
        "            \"展\": [\"展\", \"层\", \"屋\"],\n",
        "            \"的\": [\"的\", \"得\", \"地\"],\n",
        "            \"核\": [\"核\", \"该\", \"孩\"],\n",
        "            \"心\": [\"心\", \"必\", \"芯\"],\n",
        "            \"驱\": [\"驱\", \"欧\", \"区\"],\n",
        "            \"动\": [\"动\", \"运\", \"力\"],\n",
        "            \"力\": [\"力\", \"刀\", \"九\"],\n",
        "            \"。\": [\"。\", \".\", \"．\"]\n",
        "        }\n",
        "\n",
        "        return similarity_map.get(char, [char, \"?\", \"X\"])\n",
        "\n",
        "    def speculative_step(self, small_model_chars: int = 3):\n",
        "        \"\"\"执行一次投机推理步骤\"\"\"\n",
        "        if self.current_index >= len(self.target_text):\n",
        "            print(\"✓ 文本生成完成！\")\n",
        "            return False\n",
        "\n",
        "        step_info = {\n",
        "            \"step\": len(self.steps_log) + 1,\n",
        "            \"current_text\": self.generated_text,\n",
        "            \"remaining_target\": self.target_text[self.current_index:],\n",
        "            \"small_model_generated\": \"\",\n",
        "            \"validation_result\": \"\",\n",
        "            \"accepted\": False,\n",
        "            \"final_text\": \"\"\n",
        "        }\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"步骤 {step_info['step']}: 当前已生成: '{self.generated_text}'\")\n",
        "        print(f\"目标剩余: '{self.target_text[self.current_index:]}'\")\n",
        "\n",
        "        # 小模型生成候选\n",
        "        candidate = self.small_model_generate(small_model_chars)\n",
        "        step_info[\"small_model_generated\"] = candidate\n",
        "\n",
        "        print(f\"小模型生成: '{candidate}'\")\n",
        "        print(\"-\"*40)\n",
        "\n",
        "        if not candidate:\n",
        "            return False\n",
        "\n",
        "        # 大模型验证\n",
        "        is_valid, valid_part = self.large_model_validate(candidate)\n",
        "        step_info[\"validation_result\"] = f\"验证结果: {'通过' if is_valid else '拒绝'} | 有效部分: '{valid_part}'\"\n",
        "\n",
        "        print(f\"大模型验证: {step_info['validation_result']}\")\n",
        "\n",
        "        if valid_part:\n",
        "            # 接受有效部分\n",
        "            self.generated_text += valid_part\n",
        "            self.current_index += len(valid_part)\n",
        "            step_info[\"accepted\"] = True\n",
        "            step_info[\"final_text\"] = self.generated_text\n",
        "\n",
        "            print(f\"✓ 接受: '{valid_part}'\")\n",
        "            print(f\"更新文本: '{self.generated_text}'\")\n",
        "        else:\n",
        "            print(f\"✗ 全部拒绝，继续尝试...\")\n",
        "\n",
        "        # 如果验证完全失败，回退一个字符重新开始\n",
        "        if not valid_part and self.current_index > 0 and len(candidate) > 0:\n",
        "            # 单步回退策略\n",
        "            single_char = self.target_text[self.current_index]\n",
        "            self.generated_text += single_char\n",
        "            self.current_index += 1\n",
        "            print(f\"→ 回退策略: 接受单字符 '{single_char}'\")\n",
        "            print(f\"更新文本: '{self.generated_text}'\")\n",
        "\n",
        "        self.steps_log.append(step_info)\n",
        "        return True\n",
        "\n",
        "    def run_full_generation(self, max_steps: int = 20):\n",
        "        \"\"\"运行完整生成过程\"\"\"\n",
        "        print(\"开始投机推理模拟\")\n",
        "        print(f\"目标文本: '{self.target_text}'\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        steps = 0\n",
        "        while steps < max_steps and self.current_index < len(self.target_text):\n",
        "            if not self.speculative_step():\n",
        "                break\n",
        "            steps += 1\n",
        "            time.sleep(0.5)  # 模拟处理时间\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(\"生成总结:\")\n",
        "        print(f\"目标文本: '{self.target_text}'\")\n",
        "        print(f\"生成文本: '{self.generated_text}'\")\n",
        "        print(f\"准确率: {self._calculate_accuracy():.1%}\")\n",
        "        print(f\"总步数: {steps}\")\n",
        "        print(f\"文本长度: {len(self.generated_text)}\")\n",
        "\n",
        "        if self.generated_text == self.target_text:\n",
        "            print(\"完全匹配！\")\n",
        "        else:\n",
        "            print(\"存在差异\")\n",
        "\n",
        "    def _calculate_accuracy(self) -> float:\n",
        "        \"\"\"计算生成准确率\"\"\"\n",
        "        if not self.generated_text:\n",
        "            return 0.0\n",
        "\n",
        "        min_len = min(len(self.generated_text), len(self.target_text))\n",
        "        matches = sum(1 for i in range(min_len)\n",
        "                     if self.generated_text[i] == self.target_text[i])\n",
        "        return matches / len(self.target_text) if self.target_text else 0.0\n",
        "\n",
        "    def print_statistics(self):\n",
        "        \"\"\"打印详细统计信息\"\"\"\n",
        "        print(\"\\n 详细统计:\")\n",
        "        print(f\"{'步骤':<4} {'小模型输出':<10} {'验证结果':<20} {'接受':<6} {'当前文本'}\")\n",
        "        print(\"-\"*80)\n",
        "\n",
        "        for log in self.steps_log:\n",
        "            small_out = log['small_model_generated'] or 'None'\n",
        "            valid_res = log['validation_result'][:18] + '...' if len(log['validation_result']) > 18 else log['validation_result']\n",
        "            accepted = '✓' if log['accepted'] else '✗'\n",
        "            current_text = log['current_text'] + (f\"+{log['small_model_generated']}\" if log['small_model_generated'] else '')\n",
        "\n",
        "            print(f\"{log['step']:<4} {small_out:<10} {valid_res:<20} {accepted:<6} {current_text}\")\n",
        "\n",
        "\n",
        "\n",
        "def demo_rejection_sampling():\n",
        "    \"\"\"拒绝采样演示\"\"\"\n",
        "    print(\"\\n\\n 拒绝采样优化演示\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    target = \"人工智能是未来科技发展的核心驱动力。\"\n",
        "\n",
        "    print(f\"目标文本: {target}\")\n",
        "    print(\"\\n传统生成 vs 投机推理对比:\")\n",
        "\n",
        "    # 模拟传统生成\n",
        "    print(\"\\n1. 传统大模型生成（逐个字符）:\")\n",
        "    traditional_text = \"\"\n",
        "    for i, char in enumerate(target):\n",
        "        # 模拟大模型生成\n",
        "        traditional_text += char\n",
        "        print(f\"   步骤 {i+1}: 生成 '{char}' -> '{traditional_text}'\")\n",
        "        time.sleep(0.1)\n",
        "\n",
        "    # 模拟投机推理\n",
        "    print(\"\\n2. 投机推理生成（小模型提议，大模型验证）:\")\n",
        "    spec_sim = SpeculativeInferenceSimulator(target)\n",
        "    steps = 0\n",
        "    while steps < 10 and spec_sim.current_index < len(target):\n",
        "        spec_sim.speculative_step(3)  # 每次提议3个字符\n",
        "        steps += 1\n",
        "        time.sleep(0.2)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo_rejection_sampling()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 Ngram原理演示\n",
        "\n",
        "注意：由于没有固定random的seed，用例每次运行的结果由差异"
      ],
      "metadata": {
        "id": "U5bW0sqQdurD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from collections import defaultdict\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "class SimpleNGram:\n",
        "    def __init__(self, n: int = 2):\n",
        "        self.n = n  # n-gram的n值\n",
        "        self.counts = defaultdict(lambda: defaultdict(int))  # 统计计数\n",
        "        self.vocab = set()  # 词汇表\n",
        "\n",
        "    def train(self, corpus: List[List[str]]):\n",
        "        \"\"\"训练n-gram模型\"\"\"\n",
        "        for sentence in corpus:\n",
        "            tokens = ['<s>'] * (self.n-1) + sentence + ['</s>']\n",
        "            self.vocab.update(tokens)\n",
        "\n",
        "            for i in range(len(tokens) - self.n + 1):\n",
        "                context = tuple(tokens[i:i+self.n-1])  # 上下文\n",
        "                word = tokens[i+self.n-1]  # 目标词\n",
        "                self.counts[context][word] += 1\n",
        "\n",
        "    def get_probability(self, word: str, context: Tuple[str]) -> float:\n",
        "        \"\"\"获取条件概率 P(word|context)\"\"\"\n",
        "        if context not in self.counts or word not in self.counts[context]:\n",
        "            return 0.0\n",
        "\n",
        "        total = sum(self.counts[context].values())\n",
        "        return self.counts[context][word] / total\n",
        "\n",
        "    def generate_next(self, context: Tuple[str], k: int = 3) -> List[Tuple[str, float]]:\n",
        "        \"\"\"生成下一个可能的词及其概率\"\"\"\n",
        "        if context not in self.counts:\n",
        "            return []\n",
        "\n",
        "        candidates = []\n",
        "        for word, count in self.counts[context].items():\n",
        "            prob = count / sum(self.counts[context].values())\n",
        "            candidates.append((word, prob))\n",
        "\n",
        "        candidates.sort(key=lambda x: x[1], reverse=True)\n",
        "        return candidates[:k]\n",
        "\n",
        "    def generate_sentence(self, max_len: int = 10) -> str:\n",
        "        \"\"\"生成句子\"\"\"\n",
        "        context = tuple(['<s>'] * (self.n-1))\n",
        "        result = []\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            if not self.counts[context]:\n",
        "                break\n",
        "\n",
        "            # 按概率随机选择下一个词\n",
        "            words, probs = zip(*[(w, p) for w, p in self.counts[context].items()])\n",
        "            next_word = random.choices(words, weights=probs, k=1)[0]\n",
        "\n",
        "            if next_word == '</s>':\n",
        "                break\n",
        "\n",
        "            result.append(next_word)\n",
        "            context = tuple(list(context[1:]) + [next_word]) if self.n > 1 else ()\n",
        "\n",
        "        return ' '.join(result)\n",
        "\n",
        "\n",
        "# 运行演示\n",
        "if __name__ == \"__main__\":\n",
        "    # create_ngram_demo()\n",
        "\n",
        "    # 简单训练演示\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"简单训练演示\")\n",
        "\n",
        "    corpus = [\n",
        "        [\"我\", \"喜欢\", \"吃\", \"苹果\"],\n",
        "        [\"我\", \"喜欢\", \"吃\", \"香蕉\"],\n",
        "        [\"他\", \"喜欢\", \"吃\", \"西瓜\"],\n",
        "        [\"她\", \"喜欢\", \"吃\", \"葡萄\"],\n",
        "        [\"我们\", \"都\", \"喜欢\", \"水果\"],\n",
        "    ]\n",
        "\n",
        "    # 创建bigram模型\n",
        "    bigram = SimpleNGram(n=2)\n",
        "    bigram.train(corpus)\n",
        "\n",
        "    # 测试\n",
        "    test_context = tuple([\"喜欢\"])\n",
        "    next_words = bigram.generate_next(test_context)\n",
        "\n",
        "    print(f\"\\n在 '喜欢' 之后可能出现的词:\")\n",
        "    for word, prob in next_words:\n",
        "        print(f\"  '{word}': {prob:.2f}\")\n",
        "\n",
        "    # 生成句子\n",
        "    print(\"\\n生成的句子示例:\")\n",
        "    for i in range(3):\n",
        "        sentence = bigram.generate_sentence()\n",
        "        print(f\"  示例{i+1}: {sentence}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErvclLHvc9j2",
        "outputId": "bce679fc-f4ca-4ea9-ce9f-800c394a2d51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "简单训练演示\n",
            "\n",
            "在 '喜欢' 之后可能出现的词:\n",
            "  '吃': 0.80\n",
            "  '水果': 0.20\n",
            "\n",
            "生成的句子示例:\n",
            "  示例1: 我们 都 喜欢 水果\n",
            "  示例2: 她 喜欢 水果\n",
            "  示例3: 我们 都 喜欢 吃 苹果\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 vLLM运行示例\n",
        "\n",
        "运行要求：在支持vLLM的环境中运行用例。\n",
        "\n",
        "相关用例社区还在不断改进，具体可参看vLLM官网最新用例。"
      ],
      "metadata": {
        "id": "6Be3VzvleTKq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 草稿模型"
      ],
      "metadata": {
        "id": "gY0-eqCzeqlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 在vLLM中使用投机推理的示例：\n",
        "# 注意：草稿模型的功能需要在0.9.x中使用，v0.10.x中使用会报NotImplementedError错误。\n",
        "from vllm import LLM, SamplingParams\n",
        "\n",
        "\n",
        "prompts = [\n",
        "    \"InfraTech是什么类型的公众号？\",\n",
        "]\n",
        "sampling_params = SamplingParams(temperature=0.9)\n",
        "\n",
        "\n",
        "llm = LLM(\n",
        "    model=\"Qwen/Qwen3-VL-235B-A22B-Thinking\",\n",
        "    tensor_parallel_size=1,\n",
        "    speculative_config={\n",
        "        \"model\": \"Qwen/Qwen2.5-VL-3B-Instruct\",\n",
        "        \"num_speculative_tokens\": 5,\n",
        "    },\n",
        ")\n",
        "outputs = llm.generate(prompts, sampling_params)\n",
        "\n",
        "\n",
        "for output in outputs:\n",
        "    prompt = output.prompt\n",
        "    generated_text = output.outputs[0].text\n",
        "    print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\")"
      ],
      "metadata": {
        "id": "-QqEdwfUefPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 N-grams"
      ],
      "metadata": {
        "id": "pEEQCnm5ev4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vllm import LLM, SamplingParams\n",
        "\n",
        "prompts = [\n",
        "    \"如何关注InfraTech公众号？\",\n",
        "]\n",
        "sampling_params = SamplingParams(temperature=0.8, top_p=0.95)\n",
        "\n",
        "llm = LLM(\n",
        "    model=\"facebook/opt-6.7b\",\n",
        "    tensor_parallel_size=1,\n",
        "    speculative_config={\n",
        "        \"method\": \"ngram\",\n",
        "        \"num_speculative_tokens\": 5,\n",
        "        \"prompt_lookup_max\": 4,\n",
        "    },\n",
        ")\n",
        "outputs = llm.generate(prompts, sampling_params)\n",
        "\n",
        "for output in outputs:\n",
        "    prompt = output.prompt\n",
        "    generated_text = output.outputs[0].text\n",
        "    print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\")"
      ],
      "metadata": {
        "id": "_BdjX4K7ewB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Suffix Decoding/MTP"
      ],
      "metadata": {
        "id": "7-Yjihg7ewfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vllm import LLM, SamplingParams\n",
        "\n",
        "prompts = [\n",
        "    \"如何关注InfraTech公众号？\",\n",
        "]\n",
        "sampling_params = SamplingParams(temperature=0.8, top_p=0.95)\n",
        "\n",
        "llm = LLM(\n",
        "    model=\"facebook/opt-6.7b\",\n",
        "    tensor_parallel_size=1,\n",
        "    speculative_config={\n",
        "        \"method\": \"suffix\",   #\"MTP\"\n",
        "        \"num_speculative_tokens\": 5,  # 1\n",
        "    },\n",
        ")\n",
        "outputs = llm.generate(prompts, sampling_params)\n",
        "\n",
        "for output in outputs:\n",
        "    prompt = output.prompt\n",
        "    generated_text = output.outputs[0].text\n",
        "    print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\")"
      ],
      "metadata": {
        "id": "UFoCR4J-ewsp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}